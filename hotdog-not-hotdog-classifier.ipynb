{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":57440,"sourceType":"datasetVersion","datasetId":8552}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:38.657137Z","iopub.execute_input":"2025-02-04T16:05:38.657395Z","iopub.status.idle":"2025-02-04T16:05:51.250658Z","shell.execute_reply.started":"2025-02-04T16:05:38.657348Z","shell.execute_reply":"2025-02-04T16:05:51.249897Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze all convolutional layers (we only train the new layers)\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:51.251494Z","iopub.execute_input":"2025-02-04T16:05:51.252069Z","iopub.status.idle":"2025-02-04T16:05:53.986262Z","shell.execute_reply.started":"2025-02-04T16:05:51.252038Z","shell.execute_reply":"2025-02-04T16:05:53.985602Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Ensure x is built from the base_model's output\nx = base_model.output  \nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dense(1, activation='sigmoid')(x)\n\n# Now create the model\nmodel = Model(inputs=base_model.input, outputs=x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:53.987057Z","iopub.execute_input":"2025-02-04T16:05:53.987361Z","iopub.status.idle":"2025-02-04T16:05:54.027534Z","shell.execute_reply.started":"2025-02-04T16:05:53.987330Z","shell.execute_reply":"2025-02-04T16:05:54.026680Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Data Augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load images from dataset\ntrain_data = train_datagen.flow_from_directory(\n    \"/kaggle/input/hot-dog-not-hot-dog/train\",\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary'\n)\n\nval_data = val_datagen.flow_from_directory(\n    \"/kaggle/input/hot-dog-not-hot-dog/test\",\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:54.029664Z","iopub.execute_input":"2025-02-04T16:05:54.029890Z","iopub.status.idle":"2025-02-04T16:05:57.898280Z","shell.execute_reply.started":"2025-02-04T16:05:54.029871Z","shell.execute_reply":"2025-02-04T16:05:57.897662Z"}},"outputs":[{"name":"stdout","text":"Found 498 images belonging to 2 classes.\nFound 500 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(train_data.class_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:57.899416Z","iopub.execute_input":"2025-02-04T16:05:57.899662Z","iopub.status.idle":"2025-02-04T16:05:57.903744Z","shell.execute_reply.started":"2025-02-04T16:05:57.899641Z","shell.execute_reply":"2025-02-04T16:05:57.902961Z"}},"outputs":[{"name":"stdout","text":"{'hot_dog': 0, 'not_hot_dog': 1}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:57.904570Z","iopub.execute_input":"2025-02-04T16:05:57.904879Z","iopub.status.idle":"2025-02-04T16:05:57.929056Z","shell.execute_reply.started":"2025-02-04T16:05:57.904847Z","shell.execute_reply":"2025-02-04T16:05:57.928456Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Train the model\nmodel.fit(train_data, validation_data=val_data, epochs=25)\n\n# Save the trained model\nmodel.save(\"hotdog_not_hotdog.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:05:57.929799Z","iopub.execute_input":"2025-02-04T16:05:57.929998Z","iopub.status.idle":"2025-02-04T16:09:32.652257Z","shell.execute_reply.started":"2025-02-04T16:05:57.929982Z","shell.execute_reply":"2025-02-04T16:09:32.651275Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.4603 - loss: 2.5374 - val_accuracy: 0.6540 - val_loss: 0.6201\nEpoch 2/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.5232 - loss: 0.9205 - val_accuracy: 0.6820 - val_loss: 0.5833\nEpoch 3/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - accuracy: 0.6299 - loss: 0.7297 - val_accuracy: 0.6940 - val_loss: 0.6145\nEpoch 4/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.7252 - loss: 0.5441 - val_accuracy: 0.7800 - val_loss: 0.4514\nEpoch 5/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 323ms/step - accuracy: 0.7611 - loss: 0.4627 - val_accuracy: 0.7700 - val_loss: 0.5008\nEpoch 6/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.7723 - loss: 0.4495 - val_accuracy: 0.7940 - val_loss: 0.4435\nEpoch 7/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.8284 - loss: 0.3489 - val_accuracy: 0.7900 - val_loss: 0.4574\nEpoch 8/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.8650 - loss: 0.3255 - val_accuracy: 0.7500 - val_loss: 0.5497\nEpoch 9/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - accuracy: 0.8458 - loss: 0.3858 - val_accuracy: 0.7900 - val_loss: 0.4827\nEpoch 10/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.8643 - loss: 0.3227 - val_accuracy: 0.8120 - val_loss: 0.4383\nEpoch 11/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 296ms/step - accuracy: 0.8729 - loss: 0.3056 - val_accuracy: 0.7240 - val_loss: 0.6820\nEpoch 12/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.9036 - loss: 0.2701 - val_accuracy: 0.8060 - val_loss: 0.4373\nEpoch 13/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 325ms/step - accuracy: 0.8966 - loss: 0.2283 - val_accuracy: 0.7560 - val_loss: 0.6025\nEpoch 14/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - accuracy: 0.9369 - loss: 0.1865 - val_accuracy: 0.7820 - val_loss: 0.5307\nEpoch 15/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - accuracy: 0.9087 - loss: 0.2152 - val_accuracy: 0.8020 - val_loss: 0.4660\nEpoch 16/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.8999 - loss: 0.2137 - val_accuracy: 0.7860 - val_loss: 0.5184\nEpoch 17/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.9315 - loss: 0.1760 - val_accuracy: 0.7760 - val_loss: 0.6047\nEpoch 18/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - accuracy: 0.9300 - loss: 0.1902 - val_accuracy: 0.7600 - val_loss: 0.6760\nEpoch 19/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 298ms/step - accuracy: 0.9356 - loss: 0.1492 - val_accuracy: 0.7680 - val_loss: 0.6163\nEpoch 20/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.9083 - loss: 0.2111 - val_accuracy: 0.7960 - val_loss: 0.5805\nEpoch 21/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.9205 - loss: 0.1936 - val_accuracy: 0.7960 - val_loss: 0.5931\nEpoch 22/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 316ms/step - accuracy: 0.9409 - loss: 0.1456 - val_accuracy: 0.7820 - val_loss: 0.6702\nEpoch 23/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step - accuracy: 0.9408 - loss: 0.1595 - val_accuracy: 0.7860 - val_loss: 0.5624\nEpoch 24/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.9380 - loss: 0.1578 - val_accuracy: 0.8120 - val_loss: 0.5029\nEpoch 25/25\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.9129 - loss: 0.1780 - val_accuracy: 0.7340 - val_loss: 0.8631\n","output_type":"stream"}],"execution_count":7}]}